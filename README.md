# K-Means Performance Benchmark: CPU vs. GPU

This repository provides a comprehensive performance analysis of the K-Means clustering algorithm across different hardware architectures and frameworks. It demonstrates the computational advantages of parallel processing for machine learning tasks.

## ğŸš€ Features

* **CPU Baseline:** Standard sequential implementation using `scikit-learn`.
* **GPU High-Level:** Accelerated implementation using NVIDIA's `RAPIDS cuML`.
* **Custom CUDA Kernel:** A low-level, hand-written C++/CUDA implementation to demonstrate memory management and thread-level parallelism optimization.
* **Performance Profiling:** Built-in benchmarking to compare execution time and scalability across varying dataset sizes.

## ğŸ› ï¸ Tech Stack & Prerequisites

* **Languages:** Python 3.x, C++14/17
* **Frameworks/Libraries:** scikit-learn, RAPIDS cuML, NumPy, pandas, matplotlib
* **Hardware Requirements:** NVIDIA GPU (Compute Capability 6.0+). 
* *Note: The project is fully compatible with Google Colab for cloud-based execution if a local NVIDIA GPU is unavailable.*

## ğŸ“ Project Structure
```text
cuda-kmeans-benchmark/
â”œâ”€â”€ data/               # Local directory for Kaggle datasets (ignored by git)
â”œâ”€â”€ notebooks/          # Google Colab / Jupyter Notebooks for testing
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ baseline/       # Python scripts for scikit-learn CPU evaluation
â”‚   â”œâ”€â”€ rapids/         # Python scripts for cuML GPU evaluation
â”‚   â””â”€â”€ cuda/           # C++ and .cu source files for custom kernels
â”œâ”€â”€ requirements.txt    # Python dependencies
â””â”€â”€ README.md
```

## ğŸ“Š Benchmark Results

*(Note: Update this section with a visual plot once the benchmarking is complete)*

Initial tests indicate that the GPU-accelerated methods significantly outperform the CPU baseline as the number of data points and dimensions increase. Detailed metrics and speedup graphs will be added here.

## ğŸ“œ License
Distributed under the MIT License. See `LICENSE` for more information.
